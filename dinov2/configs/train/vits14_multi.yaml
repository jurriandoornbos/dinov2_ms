dino:
  head_n_prototypes: 131072
  head_bottleneck_dim: 384
ibot:
  separate_head: true
  head_n_prototypes: 131072
train:
  batch_size_per_gpu: 16 # for vit s adapt to MAX GPU can handle
  dataset_path: CustomImageDataset:split=TRAIN:root=/mnt/d/Jurrian/chipped_336:extra=None
  centering: sinkhorn_knopp # adapt "centering" # or "sinkhorn_knopp"
  output_dir: vit_ms14a
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.4
  drop_path_uniform: false
  ffn_layer: mlp #"swiglufused" or "mlp"
  block_chunks: 4
  in_chans: 4
teacher:
  momentum_teacher: 0.994
  in_chans: 4
optim:
  epochs: 100 # prolly high enough right
  weight_decay_end: 0.2
  base_lr: 5e-5  # learning rate for a batch size of 1024:2e-4; 64: 1.25e-5; 128: 2.5e-5; 256: 5e-5
  layerwise_decay: 1.0
crops:
  global_crops_size: 224  #original 224 -> 518 necessary for loading checkpoints, however, interpolation can be used to adapt the size
  local_crops_size: 98 # div/14 == a round number
